import pandas as pd
import numpy as np
from stable_baselines3 import PPO
from ai_learning.reinforcement_learning import TradingEnv
import time


def visualize_agent_behavior(model_path: str, df: pd.DataFrame):
    """
    Visualiserar hur en tr√§nad RL-agent agerar steg f√∂r steg p√• ny data.

    Args:
        model_path (str): S√∂kv√§g till den tr√§nade modellen (ex. "rl_trading_model.zip").
        df (pd.DataFrame): DataFrame med historiska data (close, momentum, volume).
    """
    # Ladda modellen
    model = PPO.load(model_path)

    # Initiera milj√∂n
    env = TradingEnv(data=df)
    obs, _ = env.reset()

    print("\nüìà STARTAR VISUALISERING AV AGENTENS BESLUT")
    print("=" * 60)
    done = False
    step = 0

    while not done:
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated

        # Visualisering i konsolen
        print(f"Steg {step:3d} | Action: {action} | Reward: {reward:8.2f} | Portf√∂ljv√§rde: {env._get_portfolio_value():.2f}")

        time.sleep(0.2)
        step += 1

    env.close()
    print("=" * 60)
    print("‚úÖ VISUALISERING SLUTF√ñRD")


if __name__ == "__main__":
    # Dummydata f√∂r demo ‚Äì byt till riktig marknadsdata f√∂r test
    np.random.seed(42)
    df = pd.DataFrame({
        "close": np.cumsum(np.random.randn(50) * 2 + 100),
        "momentum": np.random.randn(50),
        "volume": np.random.randint(100, 1000, size=50),
    })

    visualize_agent_behavior("rl_trading_model.zip", df)
