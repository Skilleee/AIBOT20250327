 import os
import openai
import argparse
import re
import platform
import subprocess
import ast
import graphviz
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from dotenv import load_dotenv
import requests

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

EXCLUDED_DIRS = {"venv", "__pycache__", ".git", "tests"}
ALLOWED_EXT = [".py"]

def read_file(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def write_file(path, content):
    filename = path.name
    if (
        "chatgpt.py" in filename or
        filename.endswith(".test.py") or
        "test_" in filename or
        str(path).startswith(".backups")
    ):
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    backup_dir = Path(".backups")
    backup_dir.mkdir(exist_ok=True)
    backup_name = f"{filename}.{timestamp}.bak"
    backup_path = backup_dir / backup_name

    with open(backup_path, "w", encoding="utf-8") as bf:
        bf.write(read_file(path))

    with open(path, "w", encoding="utf-8") as f:
        f.write(content)

def find_python_files():
    return [
        f for f in Path(".").rglob("*.py")
        if not any(part in EXCLUDED_DIRS for part in f.parts)
    ]

def map_file_dependencies(files):
    module_map = {f.stem: f for f in files}
    dependencies = defaultdict(set)

    for f in files:
        try:
            tree = ast.parse(read_file(f))
        except SyntaxError:
            continue

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    mod = alias.name.split('.')[0]
                    if mod in module_map and module_map[mod] != f:
                        dependencies[f].add(module_map[mod])
            elif isinstance(node, ast.ImportFrom):
                mod = node.module.split('.')[0] if node.module else None
                if mod in module_map and module_map[mod] != f:
                    dependencies[f].add(module_map[mod])
    return dependencies

def group_by_dependencies(files):
    deps = map_file_dependencies(files)
    groups = []
    visited = set()

    def dfs(file, group):
        if file in visited:
            return
        visited.add(file)
        group.append(file)
        for dep in deps.get(file, []):
            dfs(dep, group)

    for f in files:
        if f not in visited:
            group = []
            dfs(f, group)
            groups.append(group)
    return groups

def visualize_dependencies(deps, show_graph=False):
    print("\nBeroendekarta:")
    dot = graphviz.Digraph(comment="Python File Dependencies")

    for f, targets in deps.items():
        dot.node(f.name)
        for dep in targets:
            dot.node(dep.name)
            dot.edge(f.name, dep.name)
            print(f"{f.name} → {dep.name}")

    dot_path = Path("file_dependencies.dot")
    png_path = Path("file_dependencies.png")
    dot.save(dot_path)

    try:
        dot.render(png_path.stem, format="png", cleanup=True)
        print(f"\nGraf sparad som: {png_path}")
        if show_graph:
            open_image(png_path)
    except Exception as e:
        print(f"Kunde inte konvertera till PNG: {e}")

def open_image(path):
    system = platform.system()
    try:
        if system == "Windows":
            subprocess.run(["start", str(path)], shell=True)
        elif system == "Darwin":
            subprocess.run(["open", str(path)])
        else:
            subprocess.run(["xdg-open", str(path)])
    except Exception as e:
        print(f"Kunde inte öppna bilden: {e}")

def send_to_gpt(prompt, model="gpt-4o"):
    response = openai.ChatCompletion.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    return response.choices[0].message.content

def load_last_feedback():
    log_path = Path("improvement_log.md")
    if not log_path.exists():
        return ""
    content = log_path.read_text(encoding="utf-8").strip().split("###")[-1]
    return f"\nTidigare GPT-feedback:\n{content.strip()}" if content else ""

def save_feedback_to_log(group, full_output):
    log_path = Path("improvement_log.md")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    backup_dir = Path(".backups")
    backup_dir.mkdir(exist_ok=True)
    backup_name = f"improvement_log_{timestamp}.bak"
    (backup_dir / backup_name).write_text(log_path.read_text(encoding="utf-8") if log_path.exists() else "")

    date = datetime.now().strftime("%Y-%m-%d %H:%M")
    entry = f"\n\n### {date} – Refaktorering av {[f.name for f in group]}\n"
    feedback = extract_feedback_from_output(full_output)
    with open(log_path, "a", encoding="utf-8") as log_file:
        log_file.write(entry + feedback + "\n")

def extract_feedback_from_output(output):
    sections = output.strip().split("# FILE:")
    improvements = []
    for block in sections[1:]:
        lines = block.splitlines()
        file = lines[0].strip()
        comments = [line for line in lines if "Förbättring" in line or "kan förbättras" in line]
        if comments:
            improvements.append(f"- {file}:\n  " + "\n  ".join(comments))
    return "\n".join(improvements) if improvements else "Inga explicita förbättringar kommenterades."

def refactor_group(group, dry_run=False):
    combined = "\n\n".join([f"# FILE: {f.name}\n{read_file(f)}" for f in group])
    previous_feedback = load_last_feedback()
    prompt = (
        "Du är en expert på Python. Refaktorisera, förbättra och identifiera viktiga funktioner som saknas. "
        "Behåll logik, förbättra struktur och lägg till relevanta förbättringar. "
        "Efter varje fil: inkludera en kort reflektion över vad som förbättrats, och vad som kan förbättras ytterligare."
        f"{previous_feedback}\n\n"
        "Returnera kodfil för kodfil i formatet:\n# FILE: filnamn.py\n...\n\n" + combined
    )
    output = send_to_gpt(prompt)
    result_log = []

    blocks = output.split("# FILE:")
    for block in blocks[1:]:
        header, *content_lines = block.strip().splitlines()
        filename = header.strip()
        new_code = "\n".join(content_lines)
        for f in group:
            if f.name == filename:
                if not dry_run:
                    write_file(f, new_code)
                result_log.append(f"Refaktorerade: {filename}")
                break

    save_feedback_to_log(group, output)
    return "\n".join(result_log)

def send_telegram_message(text):
    token = os.getenv("TELEGRAM_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    if not token or not chat_id:
        return
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    requests.post(url, data={"chat_id": chat_id, "text": text})

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dry-run", action="store_true", help="Visa förändringar men skriv inte filerna")
    parser.add_argument("--group", action="store_true", help="Gruppera relaterade filer efter import")
    parser.add_argument("--show-graph", action="store_true", help="Öppna beroendegrafen automatiskt (.png)")
    parser.add_argument("--no-telegram", action="store_true", help="Skicka ingen Telegram-notis")
    args = parser.parse_args()

    files = find_python_files()
    if not files:
        print("Inga Python-filer hittades.")
        return

    all_logs = []
    if args.group:
        deps = map_file_dependencies(files)
        visualize_dependencies(deps, show_graph=args.show_graph)
        groups = group_by_dependencies(files)
        print(f"\nBearbetar {len(groups)} beroendegrupper...")
        for group in groups:
            log = refactor_group(group, dry_run=args.dry_run)
            all_logs.append(log)
    else:
        log = refactor_group(files, dry_run=args.dry_run)
        all_logs.append(log)

    summary = "\n\n".join(all_logs)
    print(summary)

    if not args.no_telegram:
        send_telegram_message(f"GPT-refaktorering klar.\n\n{summary[:3800]}")

if __name__ == "__main__":
    main()